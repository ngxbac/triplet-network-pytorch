{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.models import *\n",
    "\n",
    "from triplet_whale_loader import *\n",
    "from tripletnet import Tripletnet\n",
    "from configure import *\n",
    "from losses import *\n",
    "from embedding import *\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.base_model = resnet50(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(in_features=2048, out_features=128, bias=True)\n",
    "        # print(self.base_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"X_shape {}\".format(x.shape))\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = EmbeddingL2()\n",
    "tnet = Tripletnet(embedding)\n",
    "if config.USE_GPU:\n",
    "    tnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './runs/WhaleTriplet/checkpoint.pth.tar'\n",
      "=> loaded checkpoint './runs/WhaleTriplet/checkpoint.pth.tar' (epoch 3)\n"
     ]
    }
   ],
   "source": [
    "# optionally resume from a checkpoint\n",
    "resume = \"./runs/WhaleTriplet/checkpoint.pth.tar\"\n",
    "if os.path.isfile(resume):\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "    checkpoint = torch.load(resume)\n",
    "    # args.start_epoch = checkpoint['epoch']\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    tnet.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "            .format(resume, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "train_files = glob.glob(\"../../input/train/*.jpg\")\n",
    "test_files = glob.glob(\"../../input/test/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(config.SZ),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    img = default_image_loader(path)\n",
    "    img = test_transform(img)\n",
    "    img = img.numpy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = load_image(path)\n",
    "        imgs.append(img)\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            yield fnames, imgs\n",
    "\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "\n",
    "    raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [01:26,  3.58it/s]                         \n"
     ]
    }
   ],
   "source": [
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in tqdm(data_generator(train_files, batch=32), total=len(train_files) // 32):\n",
    "    i += 1\n",
    "    imgs = torch.from_numpy(imgs)\n",
    "    if config.USE_GPU:\n",
    "        imgs = imgs.cuda()\n",
    "    imgs = Variable(imgs)\n",
    "    predicts = tnet.get_embedded(imgs)\n",
    "    predicts = predicts.cpu().data.numpy().tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "train_preds = np.array(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [02:13,  3.67it/s]                         \n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "test_file_names = []\n",
    "for fnames, imgs in tqdm(data_generator(test_files, batch=32), total=len(test_files) // 32):\n",
    "    imgs = torch.from_numpy(imgs)\n",
    "    if config.USE_GPU:\n",
    "        imgs = imgs.cuda()\n",
    "    imgs = Variable(imgs)\n",
    "    predicts = tnet.get_embedded(imgs)\n",
    "    predicts = predicts.cpu().data.numpy().tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "test_preds = np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_str = []\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(config.TRAIN_DF.Image.values, config.TRAIN_DF.Id.values)}\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.1))\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5]\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('triplet_resnet50_new_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
